# robots.txt for GitHub Pages Betting Guide

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://yourusername.github.io/betting-guide/sitemap.xml

# Crawl-delay (optional - remove if you want faster crawling)
# Crawl-delay: 10

# Block specific bots if needed (examples below - uncomment to use)
# User-agent: BadBot
# Disallow: /

# User-agent: AnotherBadBot
# Disallow: /